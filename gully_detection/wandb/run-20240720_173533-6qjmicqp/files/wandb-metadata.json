{
    "os": "Linux-5.15.0-83-generic-x86_64-with-debian-bookworm-sid",
    "python": "3.7.13",
    "heartbeatAt": "2024-07-20T22:35:34.699020",
    "startedAt": "2024-07-20T22:35:33.553675",
    "docker": null,
    "cuda": null,
    "args": null,
    "state": "running",
    "program": "gully_detection/Evaluation.ipynb",
    "root": "/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/Gully_Detection",
    "git": {
        "remote": "git@github.com:SMATousi/Gully_Detection.git",
        "commit": "26226504fdc196e438a7c087fe138fefe55a1a30"
    },
    "email": "mohamadali.tousi@gmail.com",
    "host": "fovea",
    "username": "SMATousi",
    "executable": "/home/macula/SMATousi/.conda/envs/mac-deep/bin/python",
    "cpu_count": 16,
    "cpu_count_logical": 24,
    "cpu_freq": {
        "current": 3158.8321249999995,
        "min": 800.0,
        "max": 4716.666666666667
    },
    "cpu_freq_per_core": [
        {
            "current": 1292.312,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        }
    ],
    "disk": {
        "total": 878.0427589416504,
        "used": 79.49086380004883
    },
    "gpu": "NVIDIA GeForce RTX 3090",
    "gpu_count": 1,
    "gpu_devices": [
        {
            "name": "NVIDIA GeForce RTX 3090",
            "memory_total": 25769803776
        }
    ],
    "memory": {
        "total": 31.03472137451172
    }
}
