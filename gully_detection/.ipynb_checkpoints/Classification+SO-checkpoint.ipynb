{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c63dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedDataParallelKwargs\n",
    "import rasterio\n",
    "from model import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "import sys\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the module's directory to the sys.path\n",
    "module_dir = Path('../dem2so/').parent / \"dem2so\"\n",
    "sys.path.append(str(module_dir))\n",
    "\n",
    "# Import the module\n",
    "file1_spec = importlib.util.spec_from_file_location(\"model\", module_dir / \"model.py\")\n",
    "file1 = importlib.util.module_from_spec(file1_spec)\n",
    "file1_spec.loader.exec_module(file1)\n",
    "\n",
    "file2_spec = importlib.util.spec_from_file_location(\"dataset\", module_dir / \"dataset.py\")\n",
    "file2 = importlib.util.module_from_spec(file2_spec)\n",
    "file2_spec.loader.exec_module(file2)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf06642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstmmc\u001b[0m (\u001b[33mtousi-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/Gully_Detection/gully_detection/wandb/run-20240722_120151-7jgy57zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare/runs/7jgy57zz' target=\"_blank\">glowing-sky-17</a></strong> to <a href='https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare' target=\"_blank\">https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare/runs/7jgy57zz' target=\"_blank\">https://wandb.ai/tousi-team/RGB_DEM_2_SO_Compare/runs/7jgy57zz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model_epoch_900:v2, 196.13MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:20.6\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"RGB_DEM_2_SO_Compare\")\n",
    "artifact = run.use_artifact('tousi-team/RGB_DEM_2_SO_Compare/model_epoch_900:v2', type='model')\n",
    "artifact_dir = artifact.download(\"./artifacts/models/dem2so/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d511664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB_RasterTilesDataset_Geo(Dataset):\n",
    "    def __init__(self, dem_dir, so_dir, rgb_dir, transform=None):\n",
    "        self.dem_dir = dem_dir\n",
    "        self.so_dir = so_dir\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.transform = transform\n",
    "        # Assume all DEM, SO, and RGB files share the same tile identifiers\n",
    "        self.tile_identifiers = [f.split('_')[-1].split('.')[0] for f in os.listdir(dem_dir) if 'dem_tile' in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tile_id = self.tile_identifiers[idx]\n",
    "        dem_file = os.path.join(self.dem_dir, f'dem_tile_{tile_id}.tif')\n",
    "        so_file = os.path.join(self.so_dir, f'dem_tile_{tile_id}.tif')\n",
    "        rgb_files = [os.path.join(self.rgb_dir, f'rgb{k}_tile_{tile_id}.tif') for k in range(6)]\n",
    "\n",
    "        # Prepare sample dictionary\n",
    "        sample = {}\n",
    "\n",
    "        # Read DEM file and extract the transform\n",
    "        with rasterio.open(dem_file) as src:\n",
    "            dem_image = src.read(1)  # Read the first band\n",
    "            dem_transform = src.transform\n",
    "            sample['DEM'] = dem_image\n",
    "            sample['DEM_transform'] = dem_transform\n",
    "\n",
    "        # Read SO file and extract the transform\n",
    "        with rasterio.open(so_file) as src:\n",
    "            so_image = src.read(1)\n",
    "            so_transform = src.transform\n",
    "            sample['SO'] = so_image\n",
    "            sample['SO_transform'] = so_transform\n",
    "\n",
    "        # Read RGB files and extract their transforms\n",
    "        rgb_images = []\n",
    "        rgb_transforms = []\n",
    "        for file in rgb_files:\n",
    "            with rasterio.open(file) as src:\n",
    "                rgb_images.append(src.read([1, 2, 3]))  # Read the RGB bands\n",
    "                rgb_transforms.append(src.transform)\n",
    "        sample['RGB'] = rgb_images\n",
    "        sample['RGB_transforms'] = rgb_transforms\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa293cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f8e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "\n",
    "def save_as_geotiff(data, profile, output_path, single_value=False, image_size=128):\n",
    "    \"\"\"\n",
    "    Save a numpy array or single value as a GeoTIFF file with a given raster profile.\n",
    "    \n",
    "    :param data: Numpy array to save (2D or 3D array where 3D includes bands) or a single value.\n",
    "    :param profile: Dictionary containing raster metadata like crs, transform, etc.\n",
    "    :param output_path: Path where the GeoTIFF file will be saved\n",
    "    \"\"\"\n",
    "    # Check if data is a single value and create a 2D array with the same value\n",
    "    if single_value:\n",
    "\n",
    "        data = np.full((image_size, image_size), data, dtype=profile.get('dtype', 'float32'))\n",
    "\n",
    "    # Update the profile to accommodate the data dimensions\n",
    "    profile.update({\n",
    "        'dtype': data.dtype,\n",
    "        'height': data.shape[0],\n",
    "        'width': data.shape[1],\n",
    "        'count': 1 if data.ndim == 2 else data.shape[0],  # Assuming bands are the first dimension if 3D\n",
    "        'driver': 'GTiff',\n",
    "        'nodata': None  # Set this to the appropriate nodata value if required\n",
    "    })\n",
    "#     print(profile)\n",
    "\n",
    "    # Save the data to a GeoTIFF file\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        if data.ndim == 2:\n",
    "#             print('2')\n",
    "            dst.write(data, 1)  # Write data as the first band\n",
    "        else:\n",
    "            for i in range(data.shape[0]):\n",
    "                dst.write(data[i], i + 1)  # Write each band data\n",
    "                \n",
    "def calculate_stats(folder_path):\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".tif\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Open the TIFF file\n",
    "            with rasterio.open(file_path) as src:\n",
    "                # Read data, assuming it's a single band\n",
    "                array = src.read(1)\n",
    "                # Combine conditions for NoData and zero values\n",
    "                if src.nodata is not None:\n",
    "                    mask = (array != src.nodata) & (array != 0)\n",
    "                else:\n",
    "                    mask = (array != 0)\n",
    "                \n",
    "                # Apply mask\n",
    "                valid_data = array[mask]\n",
    "                \n",
    "                # Calculate mean and std dev and append to lists if valid data exists\n",
    "                if valid_data.size > 0:\n",
    "                    means.append(np.mean(valid_data))\n",
    "                    stds.append(np.std(valid_data))\n",
    "                else:\n",
    "                    print(f\"Warning: No valid data in file {filename} after masking. Skipping statistics.\")\n",
    "\n",
    "    # Calculate overall statistics\n",
    "    overall_mean = np.mean(means) if means else 0\n",
    "    overall_std = np.mean(stds) if stds else 0\n",
    "\n",
    "    return overall_mean, overall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Gotman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da866823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean: 216.95895\n",
      "Overall Standard Deviation: 1.2407522\n",
      "cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.94 GiB total capacity; 2.28 GiB already allocated; 2.94 MiB free; 2.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2931421/3443561899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                             number_of_in_channels=1).to(device)\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./artifacts/models/dem2so/model_epoch_900.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m             dtype=dtype)\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mps_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             untyped_storage = torch.UntypedStorage(\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             )\n\u001b[1;32m     83\u001b[0m             \u001b[0muntyped_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.94 GiB total capacity; 2.28 GiB already allocated; 2.94 MiB free; 2.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "dem_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/dem/'\n",
    "so_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/dem/'\n",
    "rgb_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/rgb/'\n",
    "pretrained_model_path = '/home/macula/SMATousi/cluster/docker-images/dem2so_more_data/pre_models/B3_rn50_moco_0099_ckpt.pth'\n",
    "\n",
    "\n",
    "mean, std = calculate_stats(dem_dir)\n",
    "print(\"Overall Mean:\", mean)\n",
    "print(\"Overall Standard Deviation:\", std)\n",
    "\n",
    "class RGB_RasterTransform_Geo:\n",
    "    \"\"\"\n",
    "    A custom transform class for raster data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        dem, so, rgb = sample['DEM'], sample['SO'], sample['RGB']\n",
    "        dem_meta, so_meta, rgb_meta = sample['DEM_transform'], sample['SO_transform'], sample['RGB_transforms']\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.hflip(dem)\n",
    "        #     so = TF.hflip(so)\n",
    "\n",
    "        # # Random vertical flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.vflip(dem)\n",
    "        #     so = TF.vflip(so)\n",
    "\n",
    "        # Convert numpy arrays to tensors\n",
    "        dem = TF.to_tensor(dem)\n",
    "        so = TF.to_tensor(so)\n",
    "        rgb_images = [TF.to_tensor(image) for image in rgb]\n",
    "        float_rgb_images = [image.float() for image in rgb_images]\n",
    "        # rgb_images = rgb_images.float()\n",
    "\n",
    "        dem = TF.normalize(dem, mean, std)\n",
    "\n",
    "        so = so.long()\n",
    "\n",
    "        return {'DEM': dem, 'SO': so.squeeze(), 'RGB': float_rgb_images,\n",
    "                'DEM_transform' : dem_meta, 'SO_transform' : so_meta, 'RGB_transforms' : rgb_meta}\n",
    "\n",
    "transform = RGB_RasterTransform_Geo()\n",
    "    \n",
    "dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir, transform=transform)\n",
    "# dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir)\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "number_of_workers = 0\n",
    "image_size = 128\n",
    "val_percent = 0.0\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "classification_model = Gully_Classifier(input_size=6*2048, hidden_size=512, output_size=1).to(device)\n",
    "\n",
    "SO_detection_model = file1.RGB_DEM_to_SO(resnet_output_size=(8, 8), \n",
    "                            fusion_output_size=(128, 128), \n",
    "                            model_choice = \"Unet_1\", \n",
    "                            input_choice='D',\n",
    "                            resnet_saved_model_path=pretrained_model_path,\n",
    "                            dropout_rate=0.5,\n",
    "                            number_of_in_channels=1).to(device)\n",
    "\n",
    "state_dict = torch.load('./artifacts/models/dem2so/model_epoch_900.pth')\n",
    "\n",
    "\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "SO_detection_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# model = RGB_DEM_to_SO(resnet_output_size=(8, 8), \n",
    "#                             fusion_output_size=(128, 128), \n",
    "#                             model_choice = \"Unet_1\", \n",
    "#                             resnet_saved_model_path=pretrained_model_path,\n",
    "#                             dropout_rate=0.5).to(device)\n",
    "\n",
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "state_dict = torch.load('./artifacts/models/model_epoch_100.pth')\n",
    "# state_dict_new = torch.load('./artifacts/new_loss/model_epoch_600.pth')\n",
    "\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "classification_model.load_state_dict(new_state_dict)\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "classification_model.eval()\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_loader)):\n",
    "# for i, batch in enumerate(train_loader):\n",
    "    \n",
    "    dem = batch['DEM'].to(device)\n",
    "    so = batch['SO'].to(device)\n",
    "    rgbs = [batch['RGB'][k].to(device) for k in range(6)]\n",
    "\n",
    "    permute_rgbs = [torch.permute(image,(0,2,1,3)) for image in rgbs]\n",
    "\n",
    "    \n",
    "    output = classification_model(permute_rgbs)\n",
    "    \n",
    "#     print(output)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     val_outputs = model(dem, permute_rgbs)\n",
    "\n",
    "#     pred = F.softmax(val_outputs, dim=1)              \n",
    "#     pred = torch.argmax(pred, dim=1).squeeze(1)\n",
    "    \n",
    "#     profile = {\n",
    "#     'transform': batch['SO_transform'],  # Example values: (west, north, xsize, ysize)\n",
    "#     'crs': 'EPSG:4326',  # Standard WGS84 CRS\n",
    "#     }\n",
    "\n",
    "    # Path to save the GeoTIFF file\n",
    "#     root_path = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/classification_results'\n",
    "#     os.makedirs(root_path, exist_ok=True)\n",
    "#     output_file_path = f'{root_path}/{i}.tif'\n",
    "    \n",
    "\n",
    "    # Call the function to save the file\n",
    "#     print(output.float().cpu().detach().numpy().squeeze())\n",
    "#     save_as_geotiff(output.float().cpu().detach().numpy().squeeze(), profile, output_file_path, single_value=True)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2856aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
