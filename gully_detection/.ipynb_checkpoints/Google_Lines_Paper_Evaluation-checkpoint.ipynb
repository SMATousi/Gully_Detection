{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b45719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedDataParallelKwargs\n",
    "import rasterio\n",
    "from model import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "import sys\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run if you have already downloaded the model\n",
    "run = wandb.init(project=\"Gully_Classification\")\n",
    "artifact = run.use_artifact('tousi-team/Gully_Classification/model_epoch_100:v0', type='model')\n",
    "artifact_dir = artifact.download(\"../weak-supervision/trained_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829fc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tiffs(input_folder, output_filepath):\n",
    "    \"\"\"\n",
    "    Merge multiple GeoTIFF files into a single larger TIFF file.\n",
    "\n",
    "    :param input_folder: Folder containing all TIFF files to merge.\n",
    "    :param output_filepath: Path to save the merged TIFF file.\n",
    "    \"\"\"\n",
    "    # Search for TIFF files in the folder\n",
    "    search_criteria = \"*.tif\"\n",
    "    query = os.path.join(input_folder, search_criteria)\n",
    "    tif_files = glob.glob(query)\n",
    "\n",
    "    # List to hold open datasets\n",
    "    src_files_to_mosaic = []\n",
    "\n",
    "    # Open and append each TIFF file to the list\n",
    "    for filepath in tif_files:\n",
    "        src = rasterio.open(filepath)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    # Merge function from rasterio\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Copy the metadata\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    # Update the metadata to reflect the number of layers\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_trans,\n",
    "        \"crs\": src_files_to_mosaic[0].crs\n",
    "    })\n",
    "\n",
    "    # Write the mosaic raster to the new file\n",
    "    with rasterio.open(output_filepath, \"w\", **out_meta) as dest:\n",
    "        for i in range(1, mosaic.shape[0]+1):\n",
    "            dest.write(mosaic[i-1], i)\n",
    "\n",
    "    # Close all rasterio opened files\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "\n",
    "    print(\"Merge completed successfully. Output saved at:\", output_filepath)\n",
    "    \n",
    "class RGB_RasterTilesDataset_Geo(Dataset):\n",
    "    def __init__(self, dem_dir, so_dir, rgb_dir, transform=None):\n",
    "        self.dem_dir = dem_dir\n",
    "        self.so_dir = dem_dir\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.transform = transform\n",
    "        # Assume all DEM, SO, and RGB files share the same tile identifiers\n",
    "        self.tile_identifiers = [f.split('_')[-1].split('.')[0] for f in os.listdir(dem_dir) if 'dem_tile' in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tile_id = self.tile_identifiers[idx]\n",
    "        dem_file = os.path.join(self.dem_dir, f'dem_tile_{tile_id}.tif')\n",
    "        so_file = os.path.join(self.so_dir, f'dem_tile_{tile_id}.tif')\n",
    "        rgb_files = [os.path.join(self.rgb_dir, f'rgb{k}_tile_{tile_id}.tif') for k in range(6)]\n",
    "\n",
    "        # Prepare sample dictionary\n",
    "        sample = {}\n",
    "\n",
    "        # Read DEM file and extract the transform\n",
    "        with rasterio.open(dem_file) as src:\n",
    "            dem_image = src.read(1)  # Read the first band\n",
    "            dem_transform = src.transform\n",
    "            sample['DEM'] = dem_image\n",
    "            sample['DEM_transform'] = dem_transform\n",
    "\n",
    "        # Read SO file and extract the transform\n",
    "        with rasterio.open(so_file) as src:\n",
    "            so_image = src.read(1)\n",
    "            so_transform = src.transform\n",
    "            sample['SO'] = so_image\n",
    "            sample['SO_transform'] = so_transform\n",
    "\n",
    "        # Read RGB files and extract their transforms\n",
    "        rgb_images = []\n",
    "        rgb_transforms = []\n",
    "        for file in rgb_files:\n",
    "            with rasterio.open(file) as src:\n",
    "                rgb_images.append(src.read([1, 2, 3]))  # Read the RGB bands\n",
    "                rgb_transforms.append(src.transform)\n",
    "        sample['RGB'] = rgb_images\n",
    "        sample['RGB_transforms'] = rgb_transforms\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6648331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d449d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "\n",
    "def save_as_geotiff(data, profile, output_path, single_value=False, image_size=128):\n",
    "    \"\"\"\n",
    "    Save a numpy array or single value as a GeoTIFF file with a given raster profile.\n",
    "    \n",
    "    :param data: Numpy array to save (2D or 3D array where 3D includes bands) or a single value.\n",
    "    :param profile: Dictionary containing raster metadata like crs, transform, etc.\n",
    "    :param output_path: Path where the GeoTIFF file will be saved\n",
    "    \"\"\"\n",
    "    # Check if data is a single value and create a 2D array with the same value\n",
    "    if single_value:\n",
    "\n",
    "        data = np.full((image_size, image_size), data, dtype=profile.get('dtype', 'float32'))\n",
    "\n",
    "    # Update the profile to accommodate the data dimensions\n",
    "    profile.update({\n",
    "        'dtype': data.dtype,\n",
    "        'height': data.shape[0],\n",
    "        'width': data.shape[1],\n",
    "        'count': 1 if data.ndim == 2 else data.shape[0],  # Assuming bands are the first dimension if 3D\n",
    "        'driver': 'GTiff',\n",
    "        'nodata': None  # Set this to the appropriate nodata value if required\n",
    "    })\n",
    "#     print(profile)\n",
    "\n",
    "    # Save the data to a GeoTIFF file\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        if data.ndim == 2:\n",
    "#             print('2')\n",
    "            dst.write(data, 1)  # Write data as the first band\n",
    "        else:\n",
    "            for i in range(data.shape[0]):\n",
    "                dst.write(data[i], i + 1)  # Write each band data\n",
    "                \n",
    "def calculate_stats(folder_path):\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".tif\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Open the TIFF file\n",
    "            with rasterio.open(file_path) as src:\n",
    "                # Read data, assuming it's a single band\n",
    "                array = src.read(1)\n",
    "                # Combine conditions for NoData and zero values\n",
    "                if src.nodata is not None:\n",
    "                    mask = (array != src.nodata) & (array != 0)\n",
    "                else:\n",
    "                    mask = (array != 0)\n",
    "                \n",
    "                # Apply mask\n",
    "                valid_data = array[mask]\n",
    "                \n",
    "                # Calculate mean and std dev and append to lists if valid data exists\n",
    "                if valid_data.size > 0:\n",
    "                    means.append(np.mean(valid_data))\n",
    "                    stds.append(np.std(valid_data))\n",
    "                else:\n",
    "                    print(f\"Warning: No valid data in file {filename} after masking. Skipping statistics.\")\n",
    "\n",
    "    # Calculate overall statistics\n",
    "    overall_mean = np.mean(means) if means else 0\n",
    "    overall_std = np.mean(stds) if stds else 0\n",
    "\n",
    "    return overall_mean, overall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02ef0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean: 257.15085\n",
      "Overall Standard Deviation: 0.64181924\n",
      "cuda\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:22<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/macula/SMATousi/Gullies/ground_truth/organized_data/Google_Lines_Paper_Evaluation/all_tiled_images/'\n",
    "\n",
    "file_name = 'downloaded_raw_15'\n",
    "\n",
    "dem_dir = os.path.join(root_dir, file_name, 'tiled_dem')\n",
    "so_dir = os.path.join(root_dir, file_name, 'tiled_so')\n",
    "rgb_dir = os.path.join(root_dir, file_name, 'tiled_rgb')\n",
    "# pretrained_model_path = '/home/macula/SMATousi/cluster/docker-images/dem2so_more_data/pre_models/B3_rn50_moco_0099_ckpt.pth'\n",
    "\n",
    "\n",
    "mean, std = calculate_stats(dem_dir)\n",
    "print(\"Overall Mean:\", mean)\n",
    "print(\"Overall Standard Deviation:\", std)\n",
    "\n",
    "class RGB_RasterTransform_Geo:\n",
    "    \"\"\"\n",
    "    A custom transform class for raster data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        dem, so, rgb = sample['DEM'], sample['SO'], sample['RGB']\n",
    "        dem_meta, so_meta, rgb_meta = sample['DEM_transform'], sample['SO_transform'], sample['RGB_transforms']\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.hflip(dem)\n",
    "        #     so = TF.hflip(so)\n",
    "\n",
    "        # # Random vertical flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.vflip(dem)\n",
    "        #     so = TF.vflip(so)\n",
    "\n",
    "        # Convert numpy arrays to tensors\n",
    "        dem = TF.to_tensor(dem)\n",
    "        so = TF.to_tensor(so)\n",
    "        rgb_images = [TF.to_tensor(image) for image in rgb]\n",
    "        float_rgb_images = [image.float() for image in rgb_images]\n",
    "        # rgb_images = rgb_images.float()\n",
    "\n",
    "        dem = TF.normalize(dem, mean, std)\n",
    "\n",
    "        so = so.long()\n",
    "\n",
    "        return {'DEM': dem, 'SO': so.squeeze(), 'RGB': float_rgb_images,\n",
    "                'DEM_transform' : dem_meta, 'SO_transform' : so_meta, 'RGB_transforms' : rgb_meta}\n",
    "\n",
    "transform = RGB_RasterTransform_Geo()\n",
    "    \n",
    "dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir, transform=transform)\n",
    "# dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir)\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "number_of_workers = 0\n",
    "image_size = 128\n",
    "val_percent = 0.0\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = Gully_Classifier(input_size=6*2048, hidden_size=512, output_size=1).to(device)\n",
    "\n",
    "# model = RGB_DEM_to_SO(resnet_output_size=(8, 8), \n",
    "#                             fusion_output_size=(128, 128), \n",
    "#                             model_choice = \"Unet_1\", \n",
    "#                             resnet_saved_model_path=pretrained_model_path,\n",
    "#                             dropout_rate=0.5).to(device)\n",
    "\n",
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "state_dict = torch.load('./artifacts/models/model_epoch_100.pth')\n",
    "# state_dict_new = torch.load('./artifacts/new_loss/model_epoch_600.pth')\n",
    "\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_loader)):\n",
    "# for i, batch in enumerate(train_loader):\n",
    "    \n",
    "    dem = batch['DEM'].to(device)\n",
    "    so = batch['SO'].to(device)\n",
    "    rgbs = [batch['RGB'][k].to(device) for k in range(6)]\n",
    "\n",
    "    permute_rgbs = [torch.permute(image,(0,2,1,3)) for image in rgbs]\n",
    "\n",
    "    \n",
    "    output = model(permute_rgbs)\n",
    "    \n",
    "#     print(output)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     val_outputs = model(dem, permute_rgbs)\n",
    "\n",
    "#     pred = F.softmax(val_outputs, dim=1)              \n",
    "#     pred = torch.argmax(pred, dim=1).squeeze(1)\n",
    "    \n",
    "    profile = {\n",
    "    'transform': batch['RGB_transforms'][0],  # Example values: (west, north, xsize, ysize)\n",
    "    'crs': 'EPSG:4326',  # Standard WGS84 CRS\n",
    "    }\n",
    "\n",
    "    # Path to save the GeoTIFF file\n",
    "    root_path = os.path.join(root_dir, file_name, 'classification_results')\n",
    "    os.makedirs(root_path, exist_ok=True)\n",
    "    output_file_path = f'{root_path}/{i}.tif'\n",
    "    \n",
    "\n",
    "    # Call the function to save the file\n",
    "#     print(output.float().cpu().detach().numpy().squeeze())\n",
    "    save_as_geotiff(output.float().cpu().detach().numpy().squeeze(), profile, output_file_path, single_value=True)\n",
    "    \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f26d4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed successfully. Output saved at: /home/macula/SMATousi/Gullies/ground_truth/organized_data/Google_Lines_Paper_Evaluation/all_tiled_images/downloaded_raw_15/merged_classification.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder =   os.path.join(root_dir, file_name, 'classification_results')\n",
    "output_filepath = os.path.join(root_dir, file_name, 'merged_classification.tif')  # Set your output file path\n",
    "\n",
    "merge_tiffs(input_folder, output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4a3970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(tensor([9.7656e-06], dtype=torch.float64), tensor([0.], dtype=torch.float64), tensor([-92.2315], dtype=torch.float64),\n",
       "       tensor([0.], dtype=torch.float64), tensor([-9.7658e-06], dtype=torch.float64), tensor([39.1265], dtype=torch.float64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['RGB_transforms'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b933b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a44cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
