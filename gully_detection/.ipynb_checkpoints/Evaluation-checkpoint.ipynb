{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b226b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedDataParallelKwargs\n",
    "import rasterio\n",
    "from model import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "import sys\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bf7628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstmmc\u001b[0m (\u001b[33mtousi-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/Gully_Detection/gully_detection/wandb/run-20240720_173533-6qjmicqp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tousi-team/Gully_Classification/runs/6qjmicqp' target=\"_blank\">spring-dream-9</a></strong> to <a href='https://wandb.ai/tousi-team/Gully_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tousi-team/Gully_Classification' target=\"_blank\">https://wandb.ai/tousi-team/Gully_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tousi-team/Gully_Classification/runs/6qjmicqp' target=\"_blank\">https://wandb.ai/tousi-team/Gully_Classification/runs/6qjmicqp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model_epoch_100:v0, 114.00MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:16.2\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"Gully_Classification\")\n",
    "artifact = run.use_artifact('tousi-team/Gully_Classification/model_epoch_100:v0', type='model')\n",
    "artifact_dir = artifact.download(\"./artifacts/models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bc3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB_RasterTilesDataset_Geo(Dataset):\n",
    "    def __init__(self, dem_dir, so_dir, rgb_dir, transform=None):\n",
    "        self.dem_dir = dem_dir\n",
    "        self.so_dir = so_dir\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.transform = transform\n",
    "        # Assume all DEM, SO, and RGB files share the same tile identifiers\n",
    "        self.tile_identifiers = [f.split('_')[-1].split('.')[0] for f in os.listdir(dem_dir) if 'dem_tile' in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_identifiers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tile_id = self.tile_identifiers[idx]\n",
    "        dem_file = os.path.join(self.dem_dir, f'dem_tile_{tile_id}.tif')\n",
    "        so_file = os.path.join(self.so_dir, f'dem_tile_{tile_id}.tif')\n",
    "        rgb_files = [os.path.join(self.rgb_dir, f'rgb{k}_tile_{tile_id}.tif') for k in range(6)]\n",
    "\n",
    "        # Prepare sample dictionary\n",
    "        sample = {}\n",
    "\n",
    "        # Read DEM file and extract the transform\n",
    "        with rasterio.open(dem_file) as src:\n",
    "            dem_image = src.read(1)  # Read the first band\n",
    "            dem_transform = src.transform\n",
    "            sample['DEM'] = dem_image\n",
    "            sample['DEM_transform'] = dem_transform\n",
    "\n",
    "        # Read SO file and extract the transform\n",
    "        with rasterio.open(so_file) as src:\n",
    "            so_image = src.read(1)\n",
    "            so_transform = src.transform\n",
    "            sample['SO'] = so_image\n",
    "            sample['SO_transform'] = so_transform\n",
    "\n",
    "        # Read RGB files and extract their transforms\n",
    "        rgb_images = []\n",
    "        rgb_transforms = []\n",
    "        for file in rgb_files:\n",
    "            with rasterio.open(file) as src:\n",
    "                rgb_images.append(src.read([1, 2, 3]))  # Read the RGB bands\n",
    "                rgb_transforms.append(src.transform)\n",
    "        sample['RGB'] = rgb_images\n",
    "        sample['RGB_transforms'] = rgb_transforms\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efd8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55fc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "\n",
    "def save_as_geotiff(data, profile, output_path, single_value=False, image_size=128):\n",
    "    \"\"\"\n",
    "    Save a numpy array or single value as a GeoTIFF file with a given raster profile.\n",
    "    \n",
    "    :param data: Numpy array to save (2D or 3D array where 3D includes bands) or a single value.\n",
    "    :param profile: Dictionary containing raster metadata like crs, transform, etc.\n",
    "    :param output_path: Path where the GeoTIFF file will be saved\n",
    "    \"\"\"\n",
    "    # Check if data is a single value and create a 2D array with the same value\n",
    "    if single_value:\n",
    "\n",
    "        data = np.full((image_size, image_size), data, dtype=profile.get('dtype', 'float32'))\n",
    "\n",
    "    # Update the profile to accommodate the data dimensions\n",
    "    profile.update({\n",
    "        'dtype': data.dtype,\n",
    "        'height': data.shape[0],\n",
    "        'width': data.shape[1],\n",
    "        'count': 1 if data.ndim == 2 else data.shape[0],  # Assuming bands are the first dimension if 3D\n",
    "        'driver': 'GTiff',\n",
    "        'nodata': None  # Set this to the appropriate nodata value if required\n",
    "    })\n",
    "#     print(profile)\n",
    "\n",
    "    # Save the data to a GeoTIFF file\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        if data.ndim == 2:\n",
    "#             print('2')\n",
    "            dst.write(data, 1)  # Write data as the first band\n",
    "        else:\n",
    "            for i in range(data.shape[0]):\n",
    "                dst.write(data[i], i + 1)  # Write each band data\n",
    "                \n",
    "def calculate_stats(folder_path):\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".tif\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Open the TIFF file\n",
    "            with rasterio.open(file_path) as src:\n",
    "                # Read data, assuming it's a single band\n",
    "                array = src.read(1)\n",
    "                # Combine conditions for NoData and zero values\n",
    "                if src.nodata is not None:\n",
    "                    mask = (array != src.nodata) & (array != 0)\n",
    "                else:\n",
    "                    mask = (array != 0)\n",
    "                \n",
    "                # Apply mask\n",
    "                valid_data = array[mask]\n",
    "                \n",
    "                # Calculate mean and std dev and append to lists if valid data exists\n",
    "                if valid_data.size > 0:\n",
    "                    means.append(np.mean(valid_data))\n",
    "                    stds.append(np.std(valid_data))\n",
    "                else:\n",
    "                    print(f\"Warning: No valid data in file {filename} after masking. Skipping statistics.\")\n",
    "\n",
    "    # Calculate overall statistics\n",
    "    overall_mean = np.mean(means) if means else 0\n",
    "    overall_std = np.mean(stds) if stds else 0\n",
    "\n",
    "    return overall_mean, overall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6efdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Gotman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f3cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean: 226.09827\n",
      "Overall Standard Deviation: 1.8296707\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3696/3696 [15:47<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# dem_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/dem/'\n",
    "# so_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/dem/'\n",
    "# rgb_dir = f'/home/macula/SMATousi/Gullies/SO_Paper/data/{field_name}/rgb/'\n",
    "# pretrained_model_path = '/home/macula/SMATousi/cluster/docker-images/dem2so_more_data/pre_models/B3_rn50_moco_0099_ckpt.pth'\n",
    "\n",
    "dem_dir = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/dem/'\n",
    "so_dir = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/dem/'\n",
    "rgb_dir = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/rgb/'\n",
    "pretrained_model_path = '/home/macula/SMATousi/cluster/docker-images/dem2so_more_data/pre_models/B3_rn50_moco_0099_ckpt.pth'\n",
    "\n",
    "\n",
    "mean, std = calculate_stats(dem_dir)\n",
    "print(\"Overall Mean:\", mean)\n",
    "print(\"Overall Standard Deviation:\", std)\n",
    "\n",
    "class RGB_RasterTransform_Geo:\n",
    "    \"\"\"\n",
    "    A custom transform class for raster data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        dem, so, rgb = sample['DEM'], sample['SO'], sample['RGB']\n",
    "        dem_meta, so_meta, rgb_meta = sample['DEM_transform'], sample['SO_transform'], sample['RGB_transforms']\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.hflip(dem)\n",
    "        #     so = TF.hflip(so)\n",
    "\n",
    "        # # Random vertical flipping\n",
    "        # if torch.rand(1) > 0.5:\n",
    "        #     dem = TF.vflip(dem)\n",
    "        #     so = TF.vflip(so)\n",
    "\n",
    "        # Convert numpy arrays to tensors\n",
    "        dem = TF.to_tensor(dem)\n",
    "        so = TF.to_tensor(so)\n",
    "        rgb_images = [TF.to_tensor(image) for image in rgb]\n",
    "        float_rgb_images = [image.float() for image in rgb_images]\n",
    "        # rgb_images = rgb_images.float()\n",
    "\n",
    "        dem = TF.normalize(dem, mean, std)\n",
    "\n",
    "        so = so.long()\n",
    "\n",
    "        return {'DEM': dem, 'SO': so.squeeze(), 'RGB': float_rgb_images,\n",
    "                'DEM_transform' : dem_meta, 'SO_transform' : so_meta, 'RGB_transforms' : rgb_meta}\n",
    "\n",
    "transform = RGB_RasterTransform_Geo()\n",
    "    \n",
    "dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir, transform=transform)\n",
    "# dataset = RGB_RasterTilesDataset_Geo(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir)\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "number_of_workers = 0\n",
    "image_size = 128\n",
    "val_percent = 0.0\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = Gully_Classifier(input_size=6*2048, hidden_size=512, output_size=1).to(device)\n",
    "\n",
    "# model = RGB_DEM_to_SO(resnet_output_size=(8, 8), \n",
    "#                             fusion_output_size=(128, 128), \n",
    "#                             model_choice = \"Unet_1\", \n",
    "#                             resnet_saved_model_path=pretrained_model_path,\n",
    "#                             dropout_rate=0.5).to(device)\n",
    "\n",
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "state_dict = torch.load('./artifacts/models/model_epoch_100.pth')\n",
    "# state_dict_new = torch.load('./artifacts/new_loss/model_epoch_600.pth')\n",
    "\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_loader)):\n",
    "# for i, batch in enumerate(train_loader):\n",
    "    \n",
    "    dem = batch['DEM'].to(device)\n",
    "    so = batch['SO'].to(device)\n",
    "    rgbs = [batch['RGB'][k].to(device) for k in range(6)]\n",
    "\n",
    "    permute_rgbs = [torch.permute(image,(0,2,1,3)) for image in rgbs]\n",
    "\n",
    "    \n",
    "    output = model(permute_rgbs)\n",
    "    \n",
    "#     print(output)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     val_outputs = model(dem, permute_rgbs)\n",
    "\n",
    "#     pred = F.softmax(val_outputs, dim=1)              \n",
    "#     pred = torch.argmax(pred, dim=1).squeeze(1)\n",
    "    \n",
    "    profile = {\n",
    "    'transform': batch['SO_transform'],  # Example values: (west, north, xsize, ysize)\n",
    "    'crs': 'EPSG:4326',  # Standard WGS84 CRS\n",
    "    }\n",
    "\n",
    "    # Path to save the GeoTIFF file\n",
    "    root_path = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/classification_results'\n",
    "    os.makedirs(root_path, exist_ok=True)\n",
    "    output_file_path = f'{root_path}/{i}.tif'\n",
    "    \n",
    "\n",
    "    # Call the function to save the file\n",
    "#     print(output.float().cpu().detach().numpy().squeeze())\n",
    "    save_as_geotiff(output.float().cpu().detach().numpy().squeeze(), profile, output_file_path, single_value=True)\n",
    "    \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11eea52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transform': Affine(tensor([1.0000e-05], dtype=torch.float64), tensor([0.], dtype=torch.float64), tensor([-91.0065], dtype=torch.float64),\n",
       "        tensor([0.], dtype=torch.float64), tensor([-1.0000e-05], dtype=torch.float64), tensor([39.1192], dtype=torch.float64)),\n",
       " 'crs': 'EPSG:4326'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4a128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed successfully. Output saved at: /home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/merged_classification_results.tif\n"
     ]
    }
   ],
   "source": [
    "def merge_tiffs(input_folder, output_filepath):\n",
    "    \"\"\"\n",
    "    Merge multiple GeoTIFF files into a single larger TIFF file.\n",
    "\n",
    "    :param input_folder: Folder containing all TIFF files to merge.\n",
    "    :param output_filepath: Path to save the merged TIFF file.\n",
    "    \"\"\"\n",
    "    # Search for TIFF files in the folder\n",
    "    search_criteria = \"*.tif\"\n",
    "    query = os.path.join(input_folder, search_criteria)\n",
    "    tif_files = glob.glob(query)\n",
    "\n",
    "    # List to hold open datasets\n",
    "    src_files_to_mosaic = []\n",
    "\n",
    "    # Open and append each TIFF file to the list\n",
    "    for filepath in tif_files:\n",
    "        src = rasterio.open(filepath)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    # Merge function from rasterio\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Copy the metadata\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    # Update the metadata to reflect the number of layers\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_trans,\n",
    "        \"crs\": src_files_to_mosaic[0].crs\n",
    "    })\n",
    "\n",
    "    # Write the mosaic raster to the new file\n",
    "    with rasterio.open(output_filepath, \"w\", **out_meta) as dest:\n",
    "        for i in range(1, mosaic.shape[0]+1):\n",
    "            dest.write(mosaic[i-1], i)\n",
    "\n",
    "    # Close all rasterio opened files\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "\n",
    "    print(\"Merge completed successfully. Output saved at:\", output_filepath)\n",
    "    \n",
    "input_folder = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/classification_results'  # Update this path to your folder path\n",
    "output_filepath = f'/home/macula/SMATousi/Gullies/ground_truth/organized_data/tiled_HUCs/HUC_070801030408/merged_classification_results.tif'  # Set your output file path\n",
    "\n",
    "merge_tiffs(input_folder, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c5c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53d6282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fd32a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a219f7a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:70: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:73: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_825724/2378972612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/rasterio/crs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initialdata, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proj_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_crs.pyx\u001b[0m in \u001b[0;36mrasterio._crs._CRS.from_dict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d48f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
