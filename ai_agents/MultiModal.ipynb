{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdb73d4-99c4-4b62-abcd-f64e00f0a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import httpx\n",
    "from langchain.chat_models import init_chat_model\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import httpx\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686bf138-1011-45d4-b065-7dcb1eb909f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(\"/home/macula/SMATousi/Gullies/ground_truth/Labeling_Tool/MO_test_data/neg_rgb_0_tile_100.tif\", \"rb\") as f:\n",
    "#     image_bytes = f.read()\n",
    "\n",
    "img = Image.open(\"/home/macula/SMATousi/Gullies/ground_truth/Labeling_Tool/MO_test_data/neg_rgb_0_tile_100.tif\")\n",
    "buf = io.BytesIO()\n",
    "img.save(buf, format=\"PNG\")  # or \"JPEG\"\n",
    "buf.seek(0)\n",
    "image_bytes = buf.read()\n",
    "\n",
    "# Step 2: Base64-encode\n",
    "b64_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8987d387-5a69-4cc0-84be-ea4c8e55e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL as pil\n",
    "# Fetch image data\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "# image = \n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3f8ce-41b9-42e5-ae22-540868440622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7901aff-ff94-4b15-97f7-d6bc970fee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass to LLM\n",
    "llm = init_chat_model(\"ollama:qwen3:14b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e26f13d-fa6d-422f-a2dc-8def8c060f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Do you see an ephemeral gully formed here? What computer vision tools would you use if you wanted to make sure that your answer is right?\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source_type\": \"base64\",\n",
    "            \"data\": b64_string,\n",
    "            \"mime_type\": \"image/png\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are talking to a king. So change your language.\"},\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\"type\": \"text\", \"text\": \"What is this image?\"},\n",
    "#             {\"type\": \"image\", \"source_type\": \"base64\", \"data\": b64_string, \"mime_type\": \"image/png\"},\n",
    "#         ],\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# message = {\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": [\n",
    "#         {\"type\": \"text\", \"text\": \"Are these two images the same?\"},\n",
    "#         {\"type\": \"image\", \"source_type\": \"url\", \"url\": image_url},\n",
    "#         {\"type\": \"image\", \"source_type\": \"url\", \"url\": image_url},\n",
    "#     ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19c6a499-e86f-4a90-ab6d-85305066c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8018e2f-ad87-4cf1-8810-6fd716e0196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking if there's an ephemeral gully in the image they provided, which is labeled as [img-0]. But since I can't actually see images, I need to explain that. Then, they want to know what computer vision tools would be used to confirm the answer.\n",
      "\n",
      "First, I should clarify that without the image, I can't directly analyze it. But I can outline the general approach. Ephemeral gullies are temporary features in arid environments, so maybe the image has a dry streambed or similar features. \n",
      "\n",
      "Next, the tools. For computer vision, maybe using object detection models like YOLO or Faster R-CNN trained on gully datasets. Image segmentation with U-Net or similar networks could help identify the gully's shape. Edge detection algorithms like Canny or Sobel might highlight the gully's edges. Classification models could determine if the image shows a gully. Also, texture analysis tools like Gabor filters or Haralick features might detect specific patterns. \n",
      "\n",
      "I should mention that the choice of tools depends on the image's quality and the gully's characteristics. Maybe include steps like preprocessing, using specific models, and post-processing. Also, note that manual verification by experts is important. \n",
      "\n",
      "Wait, did I cover all possibilities? Maybe also mention deep learning frameworks like TensorFlow or PyTorch for implementing these models. And maybe data augmentation if the dataset is small. Also, the need for a labeled dataset to train the models. \n",
      "\n",
      "I should structure the answer by first stating the inability to see the image, then explain the approach and tools, and conclude with the importance of expert validation.\n",
      "</think>\n",
      "\n",
      "Since I cannot view the image [img-0], I cannot directly analyze it to confirm the presence of an ephemeral gully. However, I can outline the **computer vision tools and techniques** that would be used to address this question systematically:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Preprocessing the Image**\n",
      "- **Tools**: OpenCV, PIL, or similar libraries.\n",
      "- **Purpose**: Enhance image quality (e.g., contrast, brightness, noise reduction) to improve detection accuracy.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Feature Detection and Segmentation**\n",
      "- **Tools**:\n",
      "  - **Edge Detection**: Canny Edge Detector, Sobel Operator (to identify linear features like gully edges).\n",
      "  - **Image Segmentation**: \n",
      "    - **Deep Learning Models**: U-Net, Mask R-CNN (for precise segmentation of gully regions).\n",
      "    - **Traditional Methods**: Watershed algorithm, region-growing (to separate gullies from surrounding terrain).\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Object Detection (if gullies are well-defined)**\n",
      "- **Tools**:\n",
      "  - **YOLO (You Only Look Once)**, **Faster R-CNN**, or **SSD** (for detecting gully-like features as objects).\n",
      "  - **Custom Models**: Trained on a dataset of labeled gullies (e.g., from satellite imagery or field surveys).\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Texture and Pattern Analysis**\n",
      "- **Tools**:\n",
      "  - **Gabor Filters**: To detect texture patterns (e.g., erosion features in gullies).\n",
      "  - **Haralick Features**: Quantify texture properties (e.g., roughness, contrast) to distinguish gullies from other landforms.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Classification (if the task is to confirm the presence of a gully)**\n",
      "- **Tools**:\n",
      "  - **Deep Learning Classifiers**: CNNs (e.g., ResNet, VGG) trained to classify regions as \"gully\" or \"non-gully.\"\n",
      "  - **Transfer Learning**: Use pre-trained models (e.g., ImageNet) fine-tuned on gully-specific datasets.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. 3D Reconstruction (if stereo imagery is available)**\n",
      "- **Tools**:\n",
      "  - **Structure from Motion (SfM)**: Using tools like OpenMVG or VisualSFM to reconstruct 3D terrain and identify gullies.\n",
      "  - **LiDAR Data**: If available, point cloud analysis (e.g., with PDAL or CloudCompare) to detect depressions or channels.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Validation and Post-Processing**\n",
      "- **Tools**:\n",
      "  - **Manual Verification**: Expert review of detected regions to confirm accuracy.\n",
      "  - **Cross-Validation**: Compare results with ground-truth data (e.g., field surveys, satellite maps).\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Considerations**\n",
      "- **Dataset Quality**: Training models requires high-quality, labeled datasets of gullies (e.g., from satellite imagery or drone surveys).\n",
      "- **Contextual Features**: Ephemeral gullies may be faint or seasonal, so models must be sensitive to subtle features.\n",
      "- **Domain Knowledge**: Geomorphological expertise is critical to interpret results and avoid false positives (e.g., confusing gullies with roads or shadows).\n",
      "\n",
      "---\n",
      "\n",
      "### **Summary**\n",
      "If you had access to [img-0], you would use a combination of **edge detection, segmentation, and classification tools** (e.g., U-Net, YOLO, Gabor filters) to identify gullies. However, **manual validation by experts** is essential to ensure accuracy, as computer vision tools may struggle with ambiguous or low-contrast features.\n"
     ]
    }
   ],
   "source": [
    "print(response.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f972e-5c83-4732-a2e1-1cc3154eed75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
